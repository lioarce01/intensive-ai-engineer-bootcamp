# ðŸ“… Bootcamp Intensivo 6 Meses â€“ AI Engineer (LLMs y Agentes) | Nov 2025

> **FilosofÃ­a 80/20**: Este bootcamp cubre el 20% esencial que explica el 80% del trabajo como AI Engineer en 2025

## ðŸŽ¯ Stack Core 2025
**Python** (71% jobs) Â· **PyTorch** Â· **Transformers** Â· **LangChain** Â· **FastAPI** Â· **Docker** Â· **Vector DBs**

| Semana    | Temas Clave                                                                                 | Proyecto                                                        | Recursos                                                                                                                                             | Prioridad   |
| --------- | ------------------------------------------------------------------------------------------- | --------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- | ----------- |
| **1-2**   | **MatemÃ¡tica mÃ­nima viable**: vectores/matrices, gradiente, backprop, probabilidad condicional | Implementar softmax, cross-entropy y backprop simple            | [3Blue1Brown â€“ Linear Algebra](https://www.youtube.com/watch?v=fNk_zzaMoSs), [StatQuest](https://www.youtube.com/watch?v=HZGCoVF3YvM) | **CrÃ­tico** |
| **3-4**   | **NLP + Prompt Engineering**: tokenizaciÃ³n, embeddings modernos, prompt engineering sistemÃ¡tico | Buscador semÃ¡ntico con interfaz + optimizaciÃ³n de prompts      | [Illustrated Word2Vec](https://jalammar.github.io/illustrated-word2vec/), Hugging Face `transformers`                                            | **CrÃ­tico** |
| **5-6**   | **AnatomÃ­a Transformer**: multi-head attention, positional encoding, reasoning models      | Mini Transformer encoder desde cero en PyTorch                  | [Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)                                                                  | **CrÃ­tico** |
| **7-8**   | **Fine-tuning moderno**: LoRA/QLoRA, PEFT, cuantizaciÃ³n 4-bit/8-bit                                              | Clasificador fine-tuneado + code generation task              | [Hugging Face PEFT](https://github.com/huggingface/peft), [Unsloth](https://github.com/unslothai/unsloth)                                                                             | **CrÃ­tico** |
| **9-10**  | **Agentes autÃ³nomos**: Model Context Protocol (MCP), AutoGen, tool calling, memory systems                                | Agente con MCP que usa APIs + tools reales | [MCP Docs](https://spec.modelcontextprotocol.io/), [AutoGen](https://microsoft.github.io/autogen/)                                                                                                       | **CrÃ­tico** |
| **11-12** | **RAG en producciÃ³n**: hybrid search, reranking, chunking strategies, Pinecone/Weaviate                          | RAG system con observabilidad y latencia <300ms                       | [Pinecone](https://www.pinecone.io/), [LlamaIndex](https://www.llamaindex.ai/), [FAISS](https://github.com/facebookresearch/faiss)                                                             | **CrÃ­tico** |
| **13-14** | **MLOps + Observabilidad**: Docker, FastAPI, MLflow, tracing distribuido, monitoring         | Pipeline reproducible con mÃ©tricas end-to-end                        | [MLflow](https://mlflow.org), [FastAPI](https://fastapi.tiangolo.com), [LangSmith](https://www.langchain.com/langsmith)                                                                                           | **CrÃ­tico**  |
| **15-16** | **Inferencia optimizada**: vLLM, TGI, cuantizaciÃ³n, batching, caching        | API de generaciÃ³n escalable con <100ms P95                   | [vLLM](https://github.com/vllm-project/vllm), [Text Generation Inference](https://github.com/huggingface/text-generation-inference)                                                                                                 | **CrÃ­tico**  |
| **17-18** | Entrenamiento LLM: dataset curation, mÃ©tricas (perplexity, BLEU), efficient training            | Mini LM entrenado desde cero con validaciÃ³n rigurosa               | [Hugging Face Course](https://huggingface.co/course), [TinyLlama](https://github.com/jzhang38/TinyLlama)                                                                                                         | Acelerador  |
| **19-20** | **Multimodal + Responsible AI**: visiÃ³n+texto, audio, Ã©tica, bias detection, RLHF                              | App multimodal con guardrails de seguridad                       | [CLIP](https://github.com/openai/CLIP), [Anthropic Safety](https://www.anthropic.com/safety)                                                                                | **CrÃ­tico**  |
| **21**    | **Portafolio tÃ©cnico**: GitHub impecable, HF Spaces, demos interactivos, documentaciÃ³n clara                                   | 3-5 proyectos pÃºblicos deployment-ready                           | [Gradio](https://www.gradio.app), [Streamlit](https://streamlit.io)                                                                                                                     | **CrÃ­tico** |
| **22-23** | **Interview prep**: system design de AI systems, RAG at scale, debugging production issues                  | Mock interviews + arquitecturas de sistemas reales                                    | [Grokking ML System Design](https://www.educative.io/courses/grokking-the-machine-learning-interview)                                                                                                                                                    | **CrÃ­tico** |
| **24**    | **EspecializaciÃ³n**: agentes empresariales, infra cloud, code generation, o alignment                       | ContribuciÃ³n OSS relevante + aplicaciones a roles              | GitHub trending AI repos                                                                                                                                                    | Acelerador  |

---

## ðŸ”¥ Habilidades No Negociables 2025

1. **Prompt Engineering** â†’ Integrado en cada rol AI (system prompts, few-shot, chain-of-thought)
2. **MLOps** â†’ 90% del trabajo es deployment + monitoring, no solo entrenar modelos
3. **Code Generation** â†’ El "killer app" de AI (Claude 42% market share para cÃ³digo)
4. **Agent Orchestration** â†’ 33% de apps enterprise tendrÃ¡n agentes autÃ³nomos para 2028
5. **Production RAG** â†’ Hybrid search, reranking, <300ms latency
6. **Responsible AI** â†’ Regulaciones nuevas + auditorÃ­as externas obligatorias

## ðŸ“Š Enfoque de Aprendizaje

- **Hands-on primero**: Cada semana = 1 proyecto funcional
- **Production-ready**: CÃ³digo que sirve en entrevistas reales
- **Open source**: Contribuir, no solo consumir
- **IteraciÃ³n rÃ¡pida**: Prototipo â†’ feedback â†’ mejorar

## ðŸŽ“ Resultado Esperado

Al final de 6 meses:
- Portfolio con 5+ proyectos production-grade
- Familiaridad con stack completo (PyTorch â†’ deployment)
- Capacidad de system design de AI systems
- Contribuciones open source verificables
- **Listo para roles mid-level AI Engineer**
