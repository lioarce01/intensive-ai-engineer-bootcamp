# üìÖ Bootcamp Intensivo 6 Meses ‚Äì AI Engineer (LLMs y Agentes)

| Semana    | Temas Clave                                                                                 | Proyecto                                                        | Recursos                                                                                                                                             |
| --------- | ------------------------------------------------------------------------------------------- | --------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| **1-2**   | Matem√°tica m√≠nima viable: vectores/matrices, gradiente, derivadas, probabilidad condicional | Implementar softmax, cross-entropy y backprop simple            | [3Blue1Brown ‚Äì Linear Algebra](https://www.youtube.com/watch?v=fNk_zzaMoSs), [StatQuest ‚Äì Probabilidad](https://www.youtube.com/watch?v=HZGCoVF3YvM) |
| **3-4**   | NLP b√°sico: tokenizaci√≥n, word2vec, GloVe, TF-IDF, embeddings modernos                      | Buscador sem√°ntico b√°sico con interfaz m√≠nima                   | [The Illustrated Word2Vec](https://jalammar.github.io/illustrated-word2vec/), Hugging Face `transformers`                                            |
| **5-6**   | Anatom√≠a de un Transformer: multi-head attention, positional encoding, encoder/decoder      | Mini Transformer encoder desde cero en PyTorch                  | [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)                                                                  |
| **7-8**   | Fine-tuning con LoRA/QLoRA, PEFT, cuantizaci√≥n                                              | Clasificador de emails/tickets reales fine-tuneado              | [Hugging Face PEFT](https://github.com/huggingface/peft), Dataset Kaggle                                                                             |
| **9-10**  | Agentes inteligentes: LangChain, funciones externas, memoria                                | Agente que responde preguntas de documentaci√≥n t√©cnica con APIs | [LangChain Docs](https://python.langchain.com)                                                                                                       |
| **11-12** | Retrieval-Augmented Generation: chunking, embeddings, FAISS/Chroma                          | Asistente corporativo sobre PDFs internos                       | [FAISS](https://github.com/facebookresearch/faiss), [Chroma](https://docs.trychroma.com)                                                             |
| **13-14** | Entrenamiento b√°sico: inicializaci√≥n, optimizadores, regularizaci√≥n                         | Clasificador desde cero con PyTorch puro                        | [PyTorch Docs](https://pytorch.org/docs/stable/index.html)                                                                                           |
| **15-16** | Entrenamiento de peque√±os LLMs: dataset curation, m√©tricas (perplexity, BLEU, Rouge)        | Mini GPT entrenado sobre corpus personalizado                   | [Hugging Face Course](https://huggingface.co/course)                                                                                                 |
| **17-18** | Infra de inferencia: vLLM, Text Generation Inference, cuantizaci√≥n, distillation            | Microservicio de generaci√≥n de texto con API REST               | [vLLM](https://github.com/vllm-project/vllm)                                                                                                         |
| **19-20** | MLOps esencial: Docker, FastAPI, MLflow, versionado de modelos                              | Pipeline reproducible y deploy en la nube                       | [MLflow](https://mlflow.org), [FastAPI](https://fastapi.tiangolo.com)                                                                                |
| **21**    | Pulido de portafolio: GitHub, Hugging Face Spaces, Gradio                                   | Repositorios limpios y demos p√∫blicos                           | [Gradio](https://www.gradio.app)                                                                                                                     |
| **22-23** | Preparaci√≥n de entrevistas: arquitecturas modernas, RAG, debugging en prod                  | Mock interviews con feedback                                    | ‚Äî                                                                                                                                                    |
| **24**    | Especializaci√≥n y networking: agentes, infra, optimizaci√≥n, alignment                       | Contribuci√≥n open source + postulaci√≥n a roles t√©cnicos         | ‚Äî                                                                                                                                                    |
