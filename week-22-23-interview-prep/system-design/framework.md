# Framework for AI System Design Interviews

## ğŸ“‹ Overview

Este framework te guÃ­a paso a paso para abordar cualquier pregunta de system design de AI/ML. La clave es ser **estructurado**, **comunicativo** y demostrar **profundidad tÃ©cnica**.

## â±ï¸ Time Management (45-60 min tÃ­pico)

| Fase | Tiempo | Objetivo |
|------|--------|----------|
| 1. Clarification & Requirements | 5-8 min | Entender el problema completamente |
| 2. High-level Design | 10-15 min | Arquitectura general y componentes |
| 3. Deep Dive | 20-30 min | Detalles tÃ©cnicos de 2-3 componentes clave |
| 4. Trade-offs & Scaling | 5-10 min | Discutir alternativas y scaling |
| 5. Q&A | 5 min | Responder preguntas del entrevistador |

## ğŸ¯ Phase 1: Clarification & Requirements (5-8 min)

**Objetivo**: Entender exactamente quÃ© estÃ¡s construyendo

### Functional Requirements
- Â¿QuÃ© debe hacer el sistema exactamente?
- Â¿CuÃ¡les son los casos de uso principales?
- Â¿QuÃ© inputs y outputs espera el sistema?
- Â¿Hay requisitos de UI/UX?

### Non-functional Requirements
- **Scale**: Â¿CuÃ¡ntos usuarios? Â¿QPS esperado?
- **Latency**: Â¿P50/P95/P99 targets? (ej: <100ms, <500ms)
- **Availability**: Â¿99.9% uptime? Â¿24/7?
- **Cost**: Â¿Budget constraints? Â¿Cost per request?
- **Quality**: Â¿QuÃ© accuracy/precision esperamos?
- **Privacy**: Â¿PII handling? Â¿GDPR compliance?

### ML-Specific Questions
- Â¿El modelo ya existe o hay que entrenarlo?
- Â¿Offline o online inference?
- Â¿Batch o real-time processing?
- Â¿Feedback loop para mejora continua?
- Â¿QuÃ© pasa si el modelo no estÃ¡ disponible? (fallback)

**Ejemplo**:
```
Pregunta: "Design a RAG system for customer support"

Buenos clarifications:
- Â¿CuÃ¡ntos documentos? (10K vs 10M es muy diferente)
- Â¿Latency target? (<300ms, <1s, <5s?)
- Â¿Solo texto o tambiÃ©n imÃ¡genes/PDFs?
- Â¿QuÃ© idiomas? (multilingÃ¼e agrega complejidad)
- Â¿Updates en tiempo real o batch diario?
- Â¿CuÃ¡ntos queries por segundo esperamos?
```

## ğŸ—ï¸ Phase 2: High-level Design (10-15 min)

**Objetivo**: DiseÃ±ar la arquitectura end-to-end

### Step 1: Identify Major Components

Componentes tÃ­picos en sistemas de AI:

1. **API Layer**: REST/GraphQL/gRPC
2. **Authentication/Authorization**: API keys, JWT, OAuth
3. **Rate Limiting**: Token bucket, leaky bucket
4. **Request Processing**: Input validation, preprocessing
5. **Model Serving**: Inference engine (vLLM, TGI, SageMaker)
6. **Caching**: Redis, Memcached (results, embeddings)
7. **Database**: Vector DB (Pinecone, Weaviate), SQL/NoSQL
8. **Message Queue**: Kafka, RabbitMQ (async processing)
9. **Monitoring**: Logs, metrics, traces (Datadog, Prometheus)
10. **Storage**: S3, GCS (models, datasets)

### Step 2: Draw High-level Architecture

**Template tÃ­pico**:

```
User â†’ Load Balancer â†’ API Gateway â†’ Application Servers
                            â†“
                       Rate Limiter
                            â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                    â†“               â†“
              Cache (Redis)    ML Service
                    â†“               â†“
              Vector DB      Model Serving
                    â†“               â†“
             Monitoring & Logging â†â”€â”€â”˜
                    â†“
             Analytics & Feedback
```

### Step 3: Define Data Flow

Describe el flujo end-to-end:

**Request Path**:
1. User sends request â†’ API Gateway
2. Authentication & rate limiting
3. Check cache (cache hit â†’ return immediately)
4. Cache miss â†’ Process request
5. Call ML service / vector search
6. Post-process results
7. Store in cache
8. Return to user
9. Log metrics & traces

**Training/Update Path** (si aplica):
1. Collect user feedback
2. Store in data warehouse
3. Periodic retraining / fine-tuning
4. A/B testing new model
5. Gradual rollout

## ğŸ” Phase 3: Deep Dive (20-30 min)

**Objetivo**: Demostrar profundidad tÃ©cnica en 2-3 componentes crÃ­ticos

### CÃ³mo elegir quÃ© deep dive hacer:
- Pregunta al entrevistador: "Â¿Hay algÃºn componente que le gustarÃ­a que profundice?"
- Si no, elige los **mÃ¡s crÃ­ticos para el sistema**: model serving, vector search, caching, etc.

### Deep Dive Topics Comunes

#### 1. Model Serving
- **Framework**: vLLM, TGI, TensorRT, TorchServe
- **Optimizations**:
  - Quantization (4-bit, 8-bit)
  - Batching (continuous batching para LLMs)
  - KV cache management
  - Speculative decoding
- **Deployment**:
  - Kubernetes con autoscaling
  - GPU allocation y scheduling
  - Health checks y graceful shutdown
- **Fallbacks**:
  - Cascade a smaller model
  - Cached responses
  - Rule-based fallback

#### 2. Vector Search / RAG
- **Indexing**:
  - Algorithm: HNSW, IVF, Product Quantization
  - Incremental updates vs full rebuild
  - Multi-tenancy (namespace per user/company)
- **Query**:
  - Hybrid search (semantic + keyword)
  - Query expansion / rewriting
  - Reranking with cross-encoder
- **Optimization**:
  - Embedding caching
  - Pre-filtering metadata
  - Top-k optimization (nprobe tuning)

#### 3. Caching Strategy
- **What to cache**:
  - Embeddings (queries, documents)
  - LLM responses (exact match + semantic match)
  - Intermediate results
- **Cache invalidation**:
  - TTL (Time to Live)
  - LRU (Least Recently Used)
  - Manual invalidation on updates
- **Implementation**:
  - Redis with clustering
  - Multi-level cache (L1: in-memory, L2: Redis)
  - Cache warming strategies

#### 4. Data Pipeline
- **Ingestion**:
  - Batch (S3 â†’ ETL â†’ Vector DB)
  - Streaming (Kafka â†’ Processing â†’ Vector DB)
  - CDC (Change Data Capture) for databases
- **Processing**:
  - Chunking strategies (fixed, semantic, recursive)
  - Metadata extraction
  - Deduplication
- **Monitoring**:
  - Data quality checks
  - Schema validation
  - Anomaly detection

## âš–ï¸ Phase 4: Trade-offs & Scaling (5-10 min)

**Objetivo**: Demostrar que entiendes los trade-offs

### Common Trade-offs

| Decision | Option A | Option B | Trade-off |
|----------|----------|----------|-----------|
| Model size | Small (7B) | Large (70B) | Latency vs quality |
| Caching | Aggressive | Conservative | Memory vs freshness |
| Indexing | HNSW | IVF | Speed vs memory |
| Search | Semantic only | Hybrid | Simplicity vs quality |
| Deployment | Single region | Multi-region | Cost vs latency |
| Database | SQL | NoSQL | Consistency vs scale |

### Scaling Considerations

**Horizontal Scaling**:
- Stateless API servers â†’ scale easily
- Load balancing (round-robin, least connections)
- Auto-scaling based on metrics (CPU, QPS)

**Vertical Scaling**:
- Larger GPU instances for models
- More memory for vector DB
- Eventually hits limits â†’ need horizontal

**Bottleneck Analysis**:
1. **If high latency**: Profile the critical path
   - Is it model inference? â†’ Optimize model
   - Is it vector search? â†’ Optimize index
   - Is it network? â†’ Add caching

2. **If high cost**: Analyze cost breakdown
   - Model serving most expensive? â†’ Use smaller model or caching
   - Vector DB expensive? â†’ Optimize storage
   - API calls expensive? â†’ Batch processing

3. **If low quality**: Debug the quality
   - Bad retrieval? â†’ Improve chunking/embeddings
   - Bad generation? â†’ Better prompts or fine-tune
   - Hallucinations? â†’ Add verification layer

### Example Scaling Path

```
Phase 1 (MVP): Monolith, single server, SQLite
   â†“ (1K users)
Phase 2: Separate API + ML service, Postgres, Redis
   â†“ (10K users)
Phase 3: Microservices, managed vector DB, load balancer
   â†“ (100K users)
Phase 4: Multi-region, auto-scaling, CDN
   â†“ (1M+ users)
```

## ğŸ¤ Phase 5: Q&A (5 min)

Preguntas comunes del entrevistador:

**Architecture**:
- "Â¿Por quÃ© elegiste X en lugar de Y?"
- "Â¿QuÃ© pasa si este componente falla?"
- "Â¿CÃ³mo manejarÃ­as un 10x de trÃ¡fico?"

**ML-Specific**:
- "Â¿CÃ³mo evaluarÃ­as la calidad del sistema?"
- "Â¿CÃ³mo detectarÃ­as model drift?"
- "Â¿CÃ³mo harÃ­as A/B testing de modelos?"

**Trade-offs**:
- "Â¿CuÃ¡l es el bottleneck principal?"
- "Â¿CÃ³mo reducirÃ­as costos sin perder calidad?"
- "Â¿DÃ³nde agregarÃ­as observability?"

## ğŸ§  Mental Models

### STAR Framework (para decisiones)
- **S**ituation: Describe el contexto
- **T**ask: QuÃ© necesitas lograr
- **A**ction: QuÃ© soluciÃ³n propones
- **R**esult: QuÃ© impacto esperas (latency, cost, quality)

### CAP Theorem (para trade-offs)
- **C**onsistency
- **A**vailability
- **P**artition tolerance

En sistemas distribuidos, solo puedes tener 2 de 3.

### Think Aloud
- Verbaliza tu proceso de pensamiento
- Explica tus assumptions
- Menciona alternativas que consideraste

## âœ… Interview Checklist

### Before Drawing
- [ ] Clarificaste todos los requisitos
- [ ] Entiendes scale, latency, cost targets
- [ ] Identificaste los casos de uso principales

### During Design
- [ ] Empezaste con high-level architecture
- [ ] Identificaste todos los componentes principales
- [ ] Definiste data flow claramente
- [ ] Hiciste deep dive en 2-3 componentes
- [ ] Discutiste trade-offs abiertamente

### Before Finishing
- [ ] Mencionaste monitoring/logging
- [ ] Discutiste failure scenarios
- [ ] Hablaste sobre scaling
- [ ] Consideraste cost optimization
- [ ] Mencionaste testing/validation

## ğŸš« Common Mistakes

1. **Jumping to details too fast**: Empieza con high-level siempre
2. **Not asking questions**: Clarifica requisitos antes de diseÃ±ar
3. **Silent designing**: Think aloud, comunica tu proceso
4. **Ignoring non-functional requirements**: Scale, latency, cost son crÃ­ticos
5. **One-size-fits-all**: No hay "perfect solution", solo trade-offs
6. **Over-engineering MVP**: Start simple, then scale
7. **Forgetting ML-specific considerations**: Model drift, feedback loops, evaluation

## ğŸ“ Example Framework Application

**Question**: "Design a semantic search system for e-commerce products"

**Step 1 - Clarification** (5 min):
- Scale: 1M products, 10K QPS
- Latency: <100ms P95
- Quality: Top 10 results with >80% relevance
- Updates: Daily batch updates of product catalog

**Step 2 - High-level** (12 min):
```
User Query â†’ API Gateway â†’ Search Service
                              â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â†“                   â†“
              Cache (Redis)      Vector DB (Pinecone)
                                        â†“
                                 Product Catalog
                                        â†“
                                  Reranking Model
                                        â†“
                                Return Top 10
```

**Step 3 - Deep Dive** (25 min):
- Vector DB: HNSW index, batch updates, monitoring
- Reranking: Cross-encoder for top 100 â†’ top 10
- Caching: Cache popular queries, 24h TTL

**Step 4 - Trade-offs** (8 min):
- Chose Pinecone (managed) vs self-hosted (Weaviate)
- Reranking adds 20ms but +15% relevance
- Daily updates vs real-time (cost vs freshness)

**Step 5 - Q&A** (5 min):
- How to handle cold start? â†’ Popular items cache
- How to evaluate? â†’ Click-through rate, conversion
- How to scale? â†’ Horizontal scaling + sharding

---

## ğŸ¯ Practice Template

Use this template to practice:

```markdown
## System Design: [Problem Name]

### Requirements
**Functional**:
-
-

**Non-functional**:
- Scale:
- Latency:
- Cost:

### High-level Architecture
[Draw diagram here]

### Components
1. **API Layer**:
2. **ML Service**:
3. **Database**:
4. **Caching**:
5. **Monitoring**:

### Data Flow
Request:
Response:

### Deep Dive
**Component 1**:
- Implementation:
- Optimization:

**Component 2**:
- Implementation:
- Optimization:

### Trade-offs
- Decision 1: X vs Y â†’ Chose X because...
- Decision 2: ...

### Scaling
- Current:
- 10x scale:
- Bottlenecks:

### Monitoring
- Metrics:
- Alerts:
- Dashboards:
```

---

**Next**: [Case Study: Chat System](./chat-system.md)
