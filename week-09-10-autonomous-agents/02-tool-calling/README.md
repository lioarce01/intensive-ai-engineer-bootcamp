# 02 - Tool/Function Calling

## ðŸ“– What is Tool Calling?

**Tool calling** (also known as function calling) allows LLMs to interact with external systems by calling predefined functions. The LLM decides *when* and *how* to use tools based on the user's request.

## ðŸŽ¯ How It Works

```
User Query: "What's the weather in Paris and convert to Fahrenheit?"
      â†“
   [LLM Reasoning]
      â†“
   Decides to use: get_weather("Paris")
      â†“
   [Execute Tool] â†’ Returns: {"temp": 20, "unit": "C"}
      â†“
   [LLM Reasoning]
      â†“
   Decides to use: convert_temp(20, "C", "F")
      â†“
   [Execute Tool] â†’ Returns: 68
      â†“
   Final Response: "It's 68Â°F in Paris"
```

## ðŸ”§ Function Definition Schema

LLMs need function schemas to understand available tools:

```python
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get current weather for a city",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "City name"
                    },
                    "units": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "Temperature units"
                    }
                },
                "required": ["city"]
            }
        }
    }
]
```

## ðŸ’¡ Key Concepts

### 1. Tool Definition
Define what the tool does and its parameters:
```python
def get_weather(city: str, units: str = "celsius") -> dict:
    """Get current weather data"""
    # Implementation
    return {"temp": 20, "condition": "sunny"}
```

### 2. Tool Registration
Register tools with the LLM:
```python
# OpenAI-style
response = client.chat.completions.create(
    model="gpt-4",
    messages=messages,
    tools=tools,  # â† Tool definitions
    tool_choice="auto"  # Let model decide
)
```

### 3. Tool Execution
Execute the tool when LLM requests it:
```python
if response.choices[0].message.tool_calls:
    for tool_call in response.choices[0].message.tool_calls:
        function_name = tool_call.function.name
        arguments = json.loads(tool_call.function.arguments)

        # Execute the actual function
        result = execute_function(function_name, arguments)
```

### 4. Return Results
Feed results back to the LLM:
```python
messages.append({
    "role": "tool",
    "tool_call_id": tool_call.id,
    "content": json.dumps(result)
})

# LLM uses result to formulate final response
final_response = client.chat.completions.create(
    model="gpt-4",
    messages=messages
)
```

## ðŸš€ Practical Example

See `weather_agent.py` for a complete working agent that:
- Accepts natural language queries
- Calls weather and unit conversion tools
- Handles multi-step reasoning
- Returns natural responses

## ðŸŽ“ Best Practices

### 1. Clear Descriptions
```python
# âŒ Bad
"description": "Gets weather"

# âœ… Good
"description": "Get current weather conditions including temperature, humidity, and conditions for a specific city"
```

### 2. Validation
```python
def get_weather(city: str, units: str = "celsius") -> dict:
    # Validate inputs
    if not city or len(city) < 2:
        return {"error": "Invalid city name"}

    if units not in ["celsius", "fahrenheit"]:
        return {"error": "Units must be 'celsius' or 'fahrenheit'"}

    # Execute
    return fetch_weather_data(city, units)
```

### 3. Error Handling
```python
try:
    result = execute_tool(name, args)
except Exception as e:
    result = {
        "error": str(e),
        "message": "Tool execution failed"
    }
```

## ðŸ“Š Common Patterns

### Sequential Tools
```
Query: "What's weather in NYC and should I bring umbrella?"
â†’ get_weather("NYC")
â†’ analyze_conditions(weather_data)
â†’ Response: "65Â°F and sunny, no umbrella needed"
```

### Parallel Tools
```
Query: "Compare weather in NYC and LA"
â†’ get_weather("NYC") + get_weather("LA") [parallel]
â†’ compare_results()
â†’ Response: "NYC is cooler at 65Â°F vs LA at 75Â°F"
```

### Conditional Tools
```
Query: "Get weather and convert if needed"
â†’ get_weather("Paris") â†’ 20Â°C
â†’ IF user_prefers_fahrenheit: convert_temp()
â†’ Response: "68Â°F in Paris"
```

## ðŸ”— Resources

- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)
- [Anthropic Tool Use](https://docs.anthropic.com/claude/docs/tool-use)
- [LangChain Tools](https://python.langchain.com/docs/modules/agents/tools/)
